{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Lake on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import databricks.koalas as ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Make sure that your AWS credentials are loaded as env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "#Normally this file should be in ~/.aws/credentials\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config.get('AWS','AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config.get('AWS','AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Load data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"s3a://udacity-dend/\"\n",
    "output_data = \"s3a://project4dend/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "#!!! change this to reading from the actual s3 bucket. but for now we're reading it locally !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o275.load.\n: com.amazonaws.services.s3.model.AmazonS3Exception: Status Code: 403, AWS Service: Amazon S3, AWS Request ID: BC93B15580C59563, AWS Error Code: null, AWS Error Message: Forbidden, S3 Extended Request ID: evQSJc23XcR54NuSpmR6X0oG0/GNGRSsZ1aLtkin8Se/sgeEG3BiRWoXvLwZDiyu7J95ll4P+ok=\n\tat com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:798)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:421)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:976)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:956)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:892)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.listStatus(S3AFileSystem.java:734)\n\tat org.apache.hadoop.fs.Globber.listStatus(Globber.java:69)\n\tat org.apache.hadoop.fs.Globber.glob(Globber.java:217)\n\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1657)\n\tat org.apache.spark.deploy.SparkHadoopUtil.globPath(SparkHadoopUtil.scala:245)\n\tat org.apache.spark.deploy.SparkHadoopUtil.globPathIfNecessary(SparkHadoopUtil.scala:255)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:549)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4ecf5976e95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# data/song_data/A/B/C/*.json           THIS WORKS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://udacity-dend/song_data/*/*/*/*.json\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# BUT THIS ONE DOESN'T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/databricks/koalas/namespace.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path, index_col, **options)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"options\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_spark_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/databricks/koalas/namespace.py\u001b[0m in \u001b[0;36mread_spark_io\u001b[0;34m(path, format, schema, index_col, **options)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"options\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mindex_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_index_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o275.load.\n: com.amazonaws.services.s3.model.AmazonS3Exception: Status Code: 403, AWS Service: Amazon S3, AWS Request ID: BC93B15580C59563, AWS Error Code: null, AWS Error Message: Forbidden, S3 Extended Request ID: evQSJc23XcR54NuSpmR6X0oG0/GNGRSsZ1aLtkin8Se/sgeEG3BiRWoXvLwZDiyu7J95ll4P+ok=\n\tat com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:798)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:421)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:232)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3528)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:976)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:956)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:892)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.listStatus(S3AFileSystem.java:734)\n\tat org.apache.hadoop.fs.Globber.listStatus(Globber.java:69)\n\tat org.apache.hadoop.fs.Globber.glob(Globber.java:217)\n\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1657)\n\tat org.apache.spark.deploy.SparkHadoopUtil.globPath(SparkHadoopUtil.scala:245)\n\tat org.apache.spark.deploy.SparkHadoopUtil.globPathIfNecessary(SparkHadoopUtil.scala:255)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:549)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "# data/song_data/A/B/C/*.json           THIS WORKS \n",
    "\n",
    "kdf = ks.read_json(\"s3a://udacity-dend/song_data/*/*/*/*.json\")   # BUT THIS ONE DOESN'T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_id            object\n",
       "artist_latitude     float64\n",
       "artist_location      object\n",
       "artist_longitude    float64\n",
       "artist_name          object\n",
       "duration            float64\n",
       "num_songs             int64\n",
       "song_id              object\n",
       "title                object\n",
       "year                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARNF6401187FB57032</td>\n",
       "      <td>40.79086</td>\n",
       "      <td>New York, NY [Manhattan]</td>\n",
       "      <td>-73.96644</td>\n",
       "      <td>Sophie B. Hawkins</td>\n",
       "      <td>305.16200</td>\n",
       "      <td>1</td>\n",
       "      <td>SONWXQJ12A8C134D94</td>\n",
       "      <td>The Ballad Of Sleeping Beauty</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>32.74863</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>-97.32925</td>\n",
       "      <td>King Curtis</td>\n",
       "      <td>326.00771</td>\n",
       "      <td>1</td>\n",
       "      <td>SODREIN12A58A7F2E5</td>\n",
       "      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARPFHN61187FB575F6</td>\n",
       "      <td>41.88415</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>-87.63241</td>\n",
       "      <td>Lupe Fiasco</td>\n",
       "      <td>279.97995</td>\n",
       "      <td>1</td>\n",
       "      <td>SOWQTQZ12A58A7B63E</td>\n",
       "      <td>Streets On Fire (Explicit Album Version)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR0IAWL1187B9A96D0</td>\n",
       "      <td>8.41770</td>\n",
       "      <td>Panama</td>\n",
       "      <td>-80.11278</td>\n",
       "      <td>Danilo Perez</td>\n",
       "      <td>197.19791</td>\n",
       "      <td>1</td>\n",
       "      <td>SONSKXP12A8C13A2C9</td>\n",
       "      <td>Native Soul</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>-13.44200</td>\n",
       "      <td>Noci (BA)</td>\n",
       "      <td>-41.99520</td>\n",
       "      <td>Bitter End</td>\n",
       "      <td>282.43546</td>\n",
       "      <td>1</td>\n",
       "      <td>SOFCHDR12AB01866EF</td>\n",
       "      <td>Living Hell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude           artist_location  artist_longitude        artist_name   duration  num_songs             song_id                                          title  year\n",
       "0  ARNF6401187FB57032         40.79086  New York, NY [Manhattan]         -73.96644  Sophie B. Hawkins  305.16200          1  SONWXQJ12A8C134D94                  The Ballad Of Sleeping Beauty  1994\n",
       "1  ARLTWXK1187FB5A3F8         32.74863            Fort Worth, TX         -97.32925        King Curtis  326.00771          1  SODREIN12A58A7F2E5  A Whiter Shade Of Pale (Live @ Fillmore West)     0\n",
       "2  ARPFHN61187FB575F6         41.88415               Chicago, IL         -87.63241        Lupe Fiasco  279.97995          1  SOWQTQZ12A58A7B63E       Streets On Fire (Explicit Album Version)     0\n",
       "3  AR0IAWL1187B9A96D0          8.41770                    Panama         -80.11278       Danilo Perez  197.19791          1  SONSKXP12A8C13A2C9                                    Native Soul  2003\n",
       "4  AREVWGE1187B9B890A        -13.44200                 Noci (BA)         -41.99520         Bitter End  282.43546          1  SOFCHDR12AB01866EF                                    Living Hell     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf.to_spark().printSchema()\n",
    "kdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>0</td>\n",
       "      <td>326.00771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Der Kleine Dompfaff</td>\n",
       "      <td>ARJIE2Y1187B994AB7</td>\n",
       "      <td>0</td>\n",
       "      <td>152.92036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Living Hell</td>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>0</td>\n",
       "      <td>282.43546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Midnight Star</td>\n",
       "      <td>ARULZCI1241B9C8611</td>\n",
       "      <td>0</td>\n",
       "      <td>335.51628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Music is what we love</td>\n",
       "      <td>AR051KA1187B98B2FF</td>\n",
       "      <td>0</td>\n",
       "      <td>261.51138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Streets On Fire (Explicit Album Version)</td>\n",
       "      <td>ARPFHN61187FB575F6</td>\n",
       "      <td>0</td>\n",
       "      <td>279.97995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The Ballad Of Sleeping Beauty</td>\n",
       "      <td>ARNF6401187FB57032</td>\n",
       "      <td>1994</td>\n",
       "      <td>305.16200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Prognosis</td>\n",
       "      <td>ARWB3G61187FB49404</td>\n",
       "      <td>2000</td>\n",
       "      <td>363.85914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Intro</td>\n",
       "      <td>AR558FS1187FB45658</td>\n",
       "      <td>2003</td>\n",
       "      <td>75.67628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Native Soul</td>\n",
       "      <td>AR0IAWL1187B9A96D0</td>\n",
       "      <td>2003</td>\n",
       "      <td>197.19791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Harajuku Girls</td>\n",
       "      <td>ARVBRGZ1187FB4675A</td>\n",
       "      <td>2004</td>\n",
       "      <td>290.55955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>City Slickers</td>\n",
       "      <td>AR8IEZO1187B99055E</td>\n",
       "      <td>2008</td>\n",
       "      <td>149.86404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          title           artist_id  year   duration\n",
       "0    1  A Whiter Shade Of Pale (Live @ Fillmore West)  ARLTWXK1187FB5A3F8     0  326.00771\n",
       "1    2                            Der Kleine Dompfaff  ARJIE2Y1187B994AB7     0  152.92036\n",
       "2    3                                    Living Hell  AREVWGE1187B9B890A     0  282.43546\n",
       "3    4                                  Midnight Star  ARULZCI1241B9C8611     0  335.51628\n",
       "4    5                          Music is what we love  AR051KA1187B98B2FF     0  261.51138\n",
       "5    6       Streets On Fire (Explicit Album Version)  ARPFHN61187FB575F6     0  279.97995\n",
       "6    7                  The Ballad Of Sleeping Beauty  ARNF6401187FB57032  1994  305.16200\n",
       "7    8                                      Prognosis  ARWB3G61187FB49404  2000  363.85914\n",
       "8    9                                          Intro  AR558FS1187FB45658  2003   75.67628\n",
       "9   10                                    Native Soul  AR0IAWL1187B9A96D0  2003  197.19791\n",
       "10  11                                 Harajuku Girls  ARVBRGZ1187FB4675A  2004  290.55955\n",
       "11  12                                  City Slickers  AR8IEZO1187B99055E  2008  149.86404"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "songs_table = (ks.sql('''\n",
    "               SELECT \n",
    "               DISTINCT\n",
    "               row_number() over (ORDER BY year,title,artist_id) id,\n",
    "               title,\n",
    "               artist_id,\n",
    "               year,\n",
    "               duration\n",
    "               FROM \n",
    "                   {kdf}''')\n",
    "              )\n",
    "\n",
    "##songs_table.to_spark().withColumn(\"id\", monotonicallyIncreasingId())\n",
    "songs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>0</td>\n",
       "      <td>326.00771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Der Kleine Dompfaff</td>\n",
       "      <td>ARJIE2Y1187B994AB7</td>\n",
       "      <td>0</td>\n",
       "      <td>152.92036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Living Hell</td>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>0</td>\n",
       "      <td>282.43546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Midnight Star</td>\n",
       "      <td>ARULZCI1241B9C8611</td>\n",
       "      <td>0</td>\n",
       "      <td>335.51628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Music is what we love</td>\n",
       "      <td>AR051KA1187B98B2FF</td>\n",
       "      <td>0</td>\n",
       "      <td>261.51138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          title           artist_id  year   duration\n",
       "0   1  A Whiter Shade Of Pale (Live @ Fillmore West)  ARLTWXK1187FB5A3F8     0  326.00771\n",
       "1   2                            Der Kleine Dompfaff  ARJIE2Y1187B994AB7     0  152.92036\n",
       "2   3                                    Living Hell  AREVWGE1187B9B890A     0  282.43546\n",
       "3   4                                  Midnight Star  ARULZCI1241B9C8611     0  335.51628\n",
       "4   5                          Music is what we love  AR051KA1187B98B2FF     0  261.51138"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Apache Parquet Introduction\n",
    "\n",
    "Apache Parquet is a columnar file format that provides optimizations to speed up queries and is a far more efficient file format than CSV or JSON, supported by many data processing systems.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Spark Write DataFrame to Parquet file format\n",
    "\n",
    "Using spark.write.parquet() function we can write Spark DataFrame to Parquet file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Spark parquet partition â€“ Improving performance\n",
    "\n",
    "> Partitioning is a feature of many databases and data processing frameworks and it is key to make jobs work at scale. We can do a parquet file partition using spark partitionBy function.\n",
    "\n",
    "> Parquet Partition creates a folder hierarchy for each spark partition; we have mentioned the first partition as year followed by artist_id hence, it creates a artist_id folder inside the year folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " #new write  . \n",
    "songs_table.to_spark().write.mode('overwrite').partitionBy(\"year\", \"artist_id\").parquet('songs/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## ---------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "kdf_logs = ks.read_json(\"data/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harmonia</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541017e+12</td>\n",
       "      <td>583</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>200</td>\n",
       "      <td>1542241826796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541017e+12</td>\n",
       "      <td>583</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>200</td>\n",
       "      <td>1542242481796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>205.45261</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541017e+12</td>\n",
       "      <td>583</td>\n",
       "      <td>Marry Me</td>\n",
       "      <td>200</td>\n",
       "      <td>1542242741796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Wyatt</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Eureka-Arcata-Fortuna, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.540872e+12</td>\n",
       "      <td>563</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1542247071796</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7....</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Austin</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Rosales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.541060e+12</td>\n",
       "      <td>521</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1542252577796</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist       auth firstName gender  itemInSession lastName     length level                               location method      page  registration  sessionId             song  status             ts                                          userAgent userId\n",
       "0     Harmonia  Logged In      Ryan      M              0    Smith  655.77751  free     San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong  1.541017e+12        583    Sehr kosmisch     200  1542241826796  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     26\n",
       "1  The Prodigy  Logged In      Ryan      M              1    Smith  260.07465  free     San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong  1.541017e+12        583  The Big Gundown     200  1542242481796  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     26\n",
       "2        Train  Logged In      Ryan      M              2    Smith  205.45261  free     San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong  1.541017e+12        583         Marry Me     200  1542242741796  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     26\n",
       "3         None  Logged In     Wyatt      M              0    Scott        NaN  free              Eureka-Arcata-Fortuna, CA    GET      Home  1.540872e+12        563             None     200  1542247071796  Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7....      9\n",
       "4         None  Logged In    Austin      M              0  Rosales        NaN  free  New York-Newark-Jersey City, NY-NJ-PA    GET      Home  1.541060e+12        521             None     200  1542252577796  Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20...     12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table = spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table =(ks.sql('''\n",
    "               SELECT \n",
    "               DISTINCT\n",
    "               userId as user_id,\n",
    "               firstName,\n",
    "               lastName,\n",
    "               gender,\n",
    "               level\n",
    "               FROM \n",
    "                   {kdf_logs}\n",
    "                    ''')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>Jordyn</td>\n",
       "      <td>Powell</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Evelin</td>\n",
       "      <td>Ayala</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>Kinsley</td>\n",
       "      <td>Young</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Gianna</td>\n",
       "      <td>Jones</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>Kinsley</td>\n",
       "      <td>Young</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id firstName lastName gender level\n",
       "0      98    Jordyn   Powell      F  free\n",
       "1      34    Evelin    Ayala      F  free\n",
       "2      85   Kinsley    Young      F  paid\n",
       "3      38    Gianna    Jones      F  free\n",
       "4      85   Kinsley    Young      F  free"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "(users_table\n",
    " .to_spark()\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .parquet('users/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARULZCI1241B9C8611</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luna Orbit Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR0IAWL1187B9A96D0</td>\n",
       "      <td>8.41770</td>\n",
       "      <td>Panama</td>\n",
       "      <td>-80.11278</td>\n",
       "      <td>Danilo Perez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARWB3G61187FB49404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton, Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Morse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>32.74863</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>-97.32925</td>\n",
       "      <td>King Curtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>-13.44200</td>\n",
       "      <td>Noci (BA)</td>\n",
       "      <td>-41.99520</td>\n",
       "      <td>Bitter End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude artist_location  artist_longitude         artist_name\n",
       "0  ARULZCI1241B9C8611              NaN                               NaN  Luna Orbit Project\n",
       "1  AR0IAWL1187B9A96D0          8.41770          Panama         -80.11278        Danilo Perez\n",
       "2  ARWB3G61187FB49404              NaN  Hamilton, Ohio               NaN         Steve Morse\n",
       "3  ARLTWXK1187FB5A3F8         32.74863  Fort Worth, TX         -97.32925         King Curtis\n",
       "4  AREVWGE1187B9B890A        -13.44200       Noci (BA)         -41.99520          Bitter End"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_table =(ks.sql('''\n",
    "               SELECT \n",
    "               DISTINCT\n",
    "               artist_id,artist_latitude,artist_location,artist_longitude,artist_name\n",
    "               FROM \n",
    "                   {kdf}''')\n",
    "              )\n",
    "artists_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARULZCI1241B9C8611</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luna Orbit Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR0IAWL1187B9A96D0</td>\n",
       "      <td>8.41770</td>\n",
       "      <td>Panama</td>\n",
       "      <td>-80.11278</td>\n",
       "      <td>Danilo Perez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARWB3G61187FB49404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton, Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Morse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>32.74863</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>-97.32925</td>\n",
       "      <td>King Curtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>-13.44200</td>\n",
       "      <td>Noci (BA)</td>\n",
       "      <td>-41.99520</td>\n",
       "      <td>Bitter End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude artist_location  artist_longitude         artist_name\n",
       "0  ARULZCI1241B9C8611              NaN                               NaN  Luna Orbit Project\n",
       "1  AR0IAWL1187B9A96D0          8.41770          Panama         -80.11278        Danilo Perez\n",
       "2  ARWB3G61187FB49404              NaN  Hamilton, Ohio               NaN         Steve Morse\n",
       "3  ARLTWXK1187FB5A3F8         32.74863  Fort Worth, TX         -97.32925         King Curtis\n",
       "4  AREVWGE1187B9B890A        -13.44200       Noci (BA)         -41.99520          Bitter End"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "(artists_table\n",
    " .to_spark()\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .partitionBy(\"artist_name\")\n",
    " .parquet('artists/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from datetime import datetime\n",
    "\n",
    "logs = spark.read.json(\"data/*.json\")\n",
    "logs =  logs.filter(logs.page == 'NextSong')\n",
    "##so we can use sql lines.\n",
    "logs.createOrReplaceTempView(\"logs_view\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "time_table = spark.sql(\"\"\"\n",
    "                            SELECT \n",
    "                            X.start_time_sub as start_time,\n",
    "                            hour(X.start_time_sub) as hour,\n",
    "                            dayofmonth(X.start_time_sub) as day,\n",
    "                            weekofyear(X.start_time_sub) as week,\n",
    "                            month(X.start_time_sub) as month,\n",
    "                            year(X.start_time_sub) as year,\n",
    "                            dayofweek(X.start_time_sub) as weekday\n",
    "                            FROM\n",
    "                            (SELECT to_timestamp(L.ts/1000) as start_time_sub\n",
    "                            FROM logs_view L\n",
    "                            WHERE L.ts IS NOT NULL\n",
    "                            ) X\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "(time_table\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .partitionBy(\"year\", \"month\")\n",
    " .parquet('time/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "kdf.to_spark().createOrReplaceTempView(\"songs_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table = spark.sql(\"\"\"\n",
    "                                SELECT monotonically_increasing_id() as songplay_id,\n",
    "                                to_timestamp(L.ts/1000) as start_time,\n",
    "                                month(to_timestamp(L.ts/1000)) as month,\n",
    "                                year(to_timestamp(L.ts/1000)) as year,\n",
    "                                L.userId as user_id,\n",
    "                                L.level as level,\n",
    "                                S.song_id as song_id,\n",
    "                                S.artist_id as artist_id,\n",
    "                                L.sessionId as session_id,\n",
    "                                L.location as location,\n",
    "                                L.userAgent as user_agent\n",
    "                                FROM logs_view L\n",
    "                                JOIN songs_view S on L.artist = S.artist_name and L.song = S.title\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "(songplays_table\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .partitionBy(\"year\", \"month\")\n",
    " .parquet('songplays/')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. Install `awscli`\n",
    "\n",
    "2. run `aws configure` \n",
    "    * AWS Access Key ID : \n",
    "    * AWS Secret Access Key : \n",
    "    * Default region name: `us-west-2`\n",
    "    * Default output format : `json`\n",
    "    \n",
    "3. **copy all the necessary files to an s3 bucket**\n",
    "\n",
    "    * Ex: `aws s3 cp <filename> s3://<bucket_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "4. **Run EMR create script with the etl job**\n",
    "\n",
    "```\n",
    "aws emr create-cluster --name \"Spark cluster with step\" \\\n",
    "    --release-label emr-5.30.1 \\\n",
    "    --applications Name=Spark \\\n",
    "    --log-uri s3://dendsparktutorial/logs/ \\\n",
    "    --ec2-attributes KeyName=emr-key \\\n",
    "    --instance-type m5.xlarge \\\n",
    "    --instance-count 3 \\\n",
    "    --bootstrap-actions Path=s3://dendsparktutorial/emr_bootstrap.sh \\\n",
    "    --steps Type=Spark,Name=\"Spark program\",ActionOnFailure=CONTINUE,Args=[--deploy-mode,cluster,--master,yarn,s3://dendsparktutorial/src/koalas_etl.py] \\\n",
    "    --use-default-roles \\\n",
    "    --auto-terminate\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
